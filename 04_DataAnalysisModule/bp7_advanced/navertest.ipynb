{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                           document  label\n",
       "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train_df = pd.read_csv('../static/data/NaverMovie/ratings_train.txt', sep='\\t')\n",
    "test_df = pd.read_csv('../static/data/NaverMovie/ratings_test.txt', sep='\\t')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((150000, 3), (50000, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "source": [
    "### Train데이터셋 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# 중복 여부 확인\n",
    "train_df['document'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(146183, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 중복 샘플 제거\n",
    "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    73342\n",
       "1    72841\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 긍정/부정 분포\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    1\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Null값 확인\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            id document  label\n",
       "25857  2172111      NaN      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25857</th>\n      <td>2172111</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_df.loc[train_df.document.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(146182, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Null값 제거\n",
    "train_df = train_df.dropna(how='any')\n",
    "train_df.shape"
   ]
  },
  {
   "source": [
    "#### 텍스트 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id            0\n",
       "document    391\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 빈 데이터가 있으면 nan으로 변경 후 확인 (이후에 dropna 진행)\n",
    "train_df['document'].replace('', np.nan, inplace=True)\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(145791, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# nan제거 / 최종 학습에 들어갈 데이터\n",
    "train_df = train_df.dropna(how='any')\n",
    "train_df.shape"
   ]
  },
  {
   "source": [
    "### Test데이터셋 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49157"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# 중복 여부 확인\n",
    "test_df['document'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(49158, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 중복 제거\n",
    "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(49157, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Null값 제거\n",
    "test_df = test_df.dropna(how='any')\n",
    "test_df.shape"
   ]
  },
  {
   "source": [
    "#### 텍스트 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id            0\n",
       "document    162\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_df['document'].replace('', np.nan, inplace=True)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48995, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# nan제거 / 최종 학습에 들어갈 데이터\n",
    "test_df = test_df.dropna(how='any')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../static/data/NaverMovie/train.tsv', sep='\\t')\n",
    "test_df.to_csv('../static/data/NaverMovie/test.tsv', sep='\\t')"
   ]
  },
  {
   "source": [
    "### 토큰화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '을']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['교도소', '이야기', '구먼', '솔직하다', '재미', '는', '없다', '평점', '조정']"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "okt.morphs('교도소 이야기구먼 솔직히 재미는 없다평점 조정', stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=145791.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b280d5e34fd4d32953094631a247dec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    from tqdm import tqdm_notebook\n",
    "    X_train = []\n",
    "    for sentence in tqdm_notebook(train_df['document']):\n",
    "        morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "        temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "        X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['아 더빙 진짜 짜증나다 목소리',\n",
       " '흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다',\n",
       " '너 무재 밓었 다그 래서 보다 추천 다']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=48995.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02174e31bb3f44088a902c07e7efd946"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "X_test = []\n",
    "for sentence in tqdm_notebook(test_df['document']):\n",
    "    morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['굳다 ㅋ', '뭐 야 평점 나쁘다 않다 점 짜다 리 더 더욱 아니다', '지루하다 않다 완전 막장 임 돈 주다 보기 에는']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'아 더빙 진짜 짜증나다 목소리'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "145791\n48995\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "source": [
    "### CountVectorizer, LogisticRegression을 이용해서 감성분석하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvecter = CountVectorizer()\n",
    "cvecter.fit(X_train)\n",
    "X_train_cvect = cvecter.transform(X_train)\n",
    "X_test_cvect = cvecter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8261659352995203"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cvect, y_train)\n",
    "pred = lr_clf.predict(X_test_cvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### 실제 테스트"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = '진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ'\n",
    "review2 = '이런 사랑영화가 다시 나올 수 있을까?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('진짜 개노잼이다 편이랑 같은 감독맞나러닝타임도 길어서 개지루함 ㄹㅇ', '이런 사랑영화가 다시 나올 수 있을까')"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "review1 = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', review1)\n",
    "review2 = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', review2)\n",
    "review1, review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'진짜 개 노잼 이다 편이 랑 같은 감독 맞나 러닝 타임 길어서 개 지루함 ㄹㅇ'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "morphs = okt.morphs(review1)\n",
    "review = ' '.join([word for word in morphs if not word in stopwords])\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그냥 review를 넣으면 shape(차원)이 맞지 않기때문에, 리스트로 변환하여 넣어야한다.\n",
    "review_cvect = cvecter.transform([review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr_clf.predict(review_cvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "morphs = okt.morphs(review2)\n",
    "review = ' '.join([word for word in morphs if not word in stopwords])\n",
    "review_cvect = cvecter.transform([review])\n",
    "pred = lr_clf.predict(review_cvect)\n",
    "pred[0]"
   ]
  },
  {
   "source": [
    "### GridSearchCV로 최적 파라미터 찾기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 31.5min finished\n",
      "{'count_vect__max_df': 9300, 'count_vect__ngram_range': (1, 2), 'lr_clf__C': 1.2} 0.8411767530231633\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'count_vect__ngram_range': [(1,2), (1,3)],\n",
    "    'count_vect__max_df': [9000, 9100, 9200, 9300],\n",
    "    'lr_clf__C': [1, 1.2, 1.5]\n",
    "}\n",
    "\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8270231656291458"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cvect, y_train)\n",
    "pred = nb.predict(X_test_cvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cn = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  4.6min finished\n",
      "{'count_vect__max_df': 8000, 'count_vect__ngram_range': (1, 4)} 0.8434814220356538\n"
     ]
    }
   ],
   "source": [
    "params_cn = {\n",
    "    'count_vect__ngram_range': [(1,4), (1,5)],\n",
    "    'count_vect__max_df': [8000, 8500, 9000]\n",
    "}\n",
    "\n",
    "grid_pipe_cn = GridSearchCV(pipeline_cn, param_grid=params_cn, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe_cn.fit(X_train, y_train)\n",
    "print(grid_pipe_cn.best_params_, grid_pipe_cn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tl = Pipeline([\n",
    "    ('tfidf_vect', CountVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 31.2min finished\n",
      "{'lr_clf__C': 1.2, 'tfidf_vect__max_df': 9300, 'tfidf_vect__ngram_range': (1, 2)} 0.8411767530231633\n"
     ]
    }
   ],
   "source": [
    "params_tl = {\n",
    "    'tfidf_vect__ngram_range': [(1,2), (1,3)],\n",
    "    'tfidf_vect__max_df': [9300, 9400, 9500, 10000],\n",
    "    'lr_clf__C': [1, 1.2, 1.5]\n",
    "}\n",
    "\n",
    "grid_pipe_tl = GridSearchCV(pipeline_tl, param_grid=params_tl, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe_tl.fit(X_train, y_train)\n",
    "print(grid_pipe_tl.best_params_, grid_pipe_tl.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tn = Pipeline([\n",
    "    ('tfidf_vect', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.9min finished\n",
      "{'tfidf_vect__max_df': 300, 'tfidf_vect__ngram_range': (1, 3)} 0.8190423277157026\n"
     ]
    }
   ],
   "source": [
    "params_tn = {\n",
    "    'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tfidf_vect__max_df': [100, 200, 300]\n",
    "}\n",
    "\n",
    "grid_pipe_tn = GridSearchCV(pipeline_tn, param_grid=params_tn, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe_tn.fit(X_train, y_train)\n",
    "print(grid_pipe_tn.best_params_, grid_pipe_tn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_tfidflr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_pipe, '../static/model/naver_countlr.pkl')\n",
    "joblib.dump(grid_pipe_cn, '../static/model/naver_countnb.pkl')\n",
    "joblib.dump(grid_pipe_tn, '../static/model/naver_tfidfnb.pkl')\n",
    "joblib.dump(grid_pipe_tl, '../static/model/naver_tfidflr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "naver_countlr = joblib.load('../static/model/naver_countlr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍지 않구나'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "morphs = okt.morphs(review)ㄴ\n",
    "review = ' '.join([word for word in morphs if not word in stopwords])\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6746fad2c898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaver_countlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "pred = naver_countlr.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}